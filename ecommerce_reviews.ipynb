{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a979fc38",
   "metadata": {},
   "source": [
    "# Analysis of E-Commerce Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b1a05b",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fd2b6a",
   "metadata": {},
   "source": [
    "- The aim of this project is to perform sentiment analysis on an E-Commerce dataset. The data is taken from https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews. This project will demonstrate sentiment analysis with two machine learning classifiers.\n",
    "\n",
    "- The 2 classifiers that will be used here are Naive Bayes Classifier and Support Vector Machine.\n",
    "\n",
    "- We will also use nltk.sentiment.vader from the SentimentIntensityAnalyzer package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e19a6c",
   "metadata": {},
   "source": [
    "#### Steps:\n",
    "\n",
    "1. Import and process data\n",
    "2. Exploratory Data Analysis and further data scraping\n",
    "3. Sentiment Analysis\n",
    " - 3.1 Naive Bayes\n",
    " - 3.2 Support Vector Machine\n",
    " - 3.3 SentimentIntensityAnalyzer \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d70fe2",
   "metadata": {},
   "source": [
    "## 1. Imports and processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc41cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd96695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Clothing E-Commerce Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae609dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                      NaN   \n",
       "1           1         1080   34                      NaN   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e744de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23486"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2108a627",
   "metadata": {},
   "source": [
    "### Removing NaN values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af4fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the columns that matter for this project\n",
    "df = df[['Review Text', 'Recommended IND']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a195b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review Text        845\n",
       "Recommended IND      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the existence of NaN values in a cell:\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d7feb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6148916d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22641"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we only removed 845 entries out of 23486, and still have substantial data to make analysis\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffb0c185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    18540\n",
       "0     4101\n",
       "Name: Recommended IND, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Recommended IND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "066b45c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.88684245395521"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18540/(18540+4101) *100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b1a652",
   "metadata": {},
   "source": [
    "As seen, we have a rather unbalanced dataset of positive and reviews. If we were to just predict all reviews are positive, we will be getting an accuracy rate of 81.8%. As such, our models should have a accuracy rate higher tham 81.8% for us to gain a comprehensive understanding of the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce65ed52",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis and further data scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e02a3ec",
   "metadata": {},
   "source": [
    "### Using Stemming  and stopwords to reduce reviews to root words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd5a3c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jiajie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "corpus = []\n",
    "\n",
    "for i,content in df.iterrows():\n",
    "    review = content[0]\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    s_stemmer = SnowballStemmer(language='english')\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    review = [s_stemmer.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f6cf3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame (corpus, columns = ['Review Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f61ee6",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c43e77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = x['Review Text']\n",
    "y = df['Recommended IND']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10798022",
   "metadata": {},
   "source": [
    "## 3.1 Build pipelines to vectorize data, then train and fit a model using Naive Bayes first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56e90f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# NaÃ¯ve Bayes:\n",
    "text_clf_nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "\n",
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "617e7a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdbc24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_nb = text_clf_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9446653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  45 1234]\n",
      " [   3 6190]]\n"
     ]
    }
   ],
   "source": [
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,predictions_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86261b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.04      0.07      1279\n",
      "           1       0.83      1.00      0.91      6193\n",
      "\n",
      "    accuracy                           0.83      7472\n",
      "   macro avg       0.89      0.52      0.49      7472\n",
      "weighted avg       0.85      0.83      0.77      7472\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a105112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834448608137045\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8357e9e",
   "metadata": {},
   "source": [
    "From the results, we can see that using Naive Bayes with TF-IDF vectorizer is not a good idea for extracting negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea298df2",
   "metadata": {},
   "source": [
    "## 3.2 Train and fit a model using Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddac9791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_lsvc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dcc4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "predictions_svm = text_clf_lsvc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96ab7125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 780  499]\n",
      " [ 311 5882]]\n"
     ]
    }
   ],
   "source": [
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,predictions_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48cb2c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66      1279\n",
      "           1       0.92      0.95      0.94      6193\n",
      "\n",
      "    accuracy                           0.89      7472\n",
      "   macro avg       0.82      0.78      0.80      7472\n",
      "weighted avg       0.89      0.89      0.89      7472\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16b36353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8915952890792291\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc9b992",
   "metadata": {},
   "source": [
    "## 3.3 Sentiment Analysis using SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fceb04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "932d02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scores'] = df['Review Text'].apply(lambda review: sid.polarity_scores(review))\n",
    "\n",
    "df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "df['comp_score'] = df['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "964ad112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['actual_score'] = df['Recommended IND'].apply(lambda c: 'pos' if c ==1 else 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e24406ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "      <th>actual_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.272, 'pos': 0.728, 'comp...</td>\n",
       "      <td>0.8932</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.664, 'pos': 0.336, 'comp...</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.027, 'neu': 0.792, 'pos': 0.181, 'co...</td>\n",
       "      <td>0.9427</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.226, 'neu': 0.34, 'pos': 0.434, 'com...</td>\n",
       "      <td>0.5727</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.7, 'pos': 0.3, 'compound...</td>\n",
       "      <td>0.9291</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...                1   \n",
       "2  I had such high hopes for this dress and reall...                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...                1   \n",
       "4  This shirt is very flattering to all due to th...                1   \n",
       "\n",
       "                                              scores  compound comp_score  \\\n",
       "0  {'neg': 0.0, 'neu': 0.272, 'pos': 0.728, 'comp...    0.8932        pos   \n",
       "1  {'neg': 0.0, 'neu': 0.664, 'pos': 0.336, 'comp...    0.9729        pos   \n",
       "2  {'neg': 0.027, 'neu': 0.792, 'pos': 0.181, 'co...    0.9427        pos   \n",
       "3  {'neg': 0.226, 'neu': 0.34, 'pos': 0.434, 'com...    0.5727        pos   \n",
       "4  {'neg': 0.0, 'neu': 0.7, 'pos': 0.3, 'compound...    0.9291        pos   \n",
       "\n",
       "  actual_score  \n",
       "0          pos  \n",
       "1          pos  \n",
       "2          neg  \n",
       "3          pos  \n",
       "4          pos  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db4097c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b86c6dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8375955125656994"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df['actual_score'],df['comp_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc8eb298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.65      0.23      0.34      4101\n",
      "         pos       0.85      0.97      0.91     18540\n",
      "\n",
      "    accuracy                           0.84     22641\n",
      "   macro avg       0.75      0.60      0.62     22641\n",
      "weighted avg       0.81      0.84      0.80     22641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['actual_score'],df['comp_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d104e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some negative reviews:\n",
      "\n",
      "I ordered this in carbon for store pick up, and had a ton of stuff (as always) to try on and used this top to pair (skirts and pants). everything went with it. the color is really nice charcoal with shimmer, and went well with pencil skirts, flare pants, etc. my only compaint is it is a bit big, sleeves are long and it doesn't go in petite. also a bit loose for me, but no xxs... so i kept it and wil ldecide later since the light color is already sold out in hte smallest size...\n",
      "\n",
      "\n",
      "I'm 5\"5' and 125 lbs. i ordered the s petite to make sure the length wasn't too long. i typically wear an xs regular in retailer dresses. if you're less busty (34b cup or smaller), a s petite will fit you perfectly (snug, but not tight). i love that i could dress it up for a party, or down for work. i love that the tulle is longer then the fabric underneath.\n",
      "\n",
      "\n",
      "3 tags sewn in, 2 small (about 1'' long) and 1 huge (about 2'' x 3''). very itchy so i cut them out. then the thread left behind was plasticy and even more itchy! how can you make an intimates item with such itchy tags? not comfortable at all! also - i love bralettes and wear them all the time including to work. i am a b cup. however, this one is so thin and flimsy that it gives no support even to a b cup - so for me this would only be a lounging bralette - if it wasn't so itchy!\n",
      "\n",
      "\n",
      "The zipper broke on this piece the first time i wore it. very disappointing since i love the design. i'm actually going to try to replace the zipper myself with something stronger, but annoying that it's come to that.\n",
      "\n",
      "\n",
      "Really cute piece, but it's huge. i ordered an xxs petite and it was unfortunately extremely wide and not flattering. returning.\n"
     ]
    }
   ],
   "source": [
    "print('Some negative reviews:')\n",
    "print('')\n",
    "print(df[df['comp_score'] == 'neg'].iloc[0,0])\n",
    "print('\\n')\n",
    "print(df[df['comp_score'] == 'neg'].iloc[1,0])\n",
    "print('\\n')\n",
    "print(df[df['comp_score'] == 'neg'].iloc[2,0])\n",
    "print('\\n')\n",
    "print(df[df['comp_score'] == 'neg'].iloc[3,0])\n",
    "print('\\n')\n",
    "print(df[df['comp_score'] == 'neg'].iloc[4,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837ed29",
   "metadata": {},
   "source": [
    "Based on the findings, use of support vector machine is the best classifier that gives us higher accuracy, precision and recall score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
